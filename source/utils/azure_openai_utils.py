"""
@created_by ayaan
@created_at 2023.05.08
"""
import os
import requests
import time
from custom_exception import APIException
from utils.common_utils import CommonUtils
from collections import OrderedDict
from azure.core.credentials import AzureKeyCredential
from azure.search.documents.indexes.aio import SearchIndexerClient
from azure.search.documents.indexes.aio import SearchIndexClient

# LangCahin & OpenAI íŒ¨í‚¤ì§€
import openai
from langchain.chat_models import AzureChatOpenAI

# from langchain.vectorstores import Chroma
from langchain.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.embeddings import OpenAIEmbeddings

from dotenv import load_dotenv

# Log DB Insert
from database import MysqlEngine
from domains.models import ChatRequestHistory

load_dotenv()


class AzureOpenAIUtils:
    """Azure OpenAI Utilities"""

    azure_search_key = os.environ.get("SEARCH_KEY")
    azure_search_endpoint = os.environ.get("SEARCH_ENDPOINT")
    azure_search_api_version = "2021-04-30-preview"
    azure_openai_key = os.environ.get("OPEN_AI_KEY")
    azure_openai_endpoint = os.environ.get("OPEN_AI_ENDPOINT")
    azure_openai_api_version = "2023-03-15-preview"
    pre_prompt = """
    """

    def __init__(self):
        self.headers = {"Content-Type": "application/json", "api-key": self.azure_search_key}
        self.params = {"api-version": self.azure_search_api_version}  # ìµœì‹  Preview ë²„ì „ 2021-04-30-preview

        self.cognitive_search_credential = AzureKeyCredential(self.azure_search_key)

        # Azure OpenAI ì—°ê²° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        openai.api_type = "azure"  # ì¤‘ìš”!
        openai.api_version = self.azure_openai_api_version  # ìµœì‹  preview ë²„ì „ 2023-03-15-preview
        openai.api_base = self.azure_openai_endpoint
        openai.api_key = self.azure_openai_key

    async def get_index(self, index_name):
        """cognitive Search Get Index"""
        search_index_client = SearchIndexClient(self.azure_search_endpoint, self.cognitive_search_credential)
        index = await search_index_client.get_index(index_name)
        await search_index_client.close()
        return index

    async def get_indexer(self, indexer_name):
        """cognitive Search Get Indexer"""
        search_indexer_client = SearchIndexerClient(self.azure_search_endpoint, self.cognitive_search_credential)
        indexer = await search_indexer_client.get_index(indexer_name)
        await search_indexer_client.close()
        return indexer

    async def get_index_list(self):
        """cognitive Search Get Index List"""
        search_index_client = SearchIndexClient(self.azure_search_endpoint, self.cognitive_search_credential)
        index_list = []
        async for index in search_index_client.list_indexes():
            index_list.append({"index_name": index.name})

        await search_index_client.close()

        return index_list

    async def get_indexer_list(self):
        """cognitive Search Get Indexer List"""
        search_indexer_client = SearchIndexerClient(self.azure_search_endpoint, self.cognitive_search_credential)
        indexer_list = []
        for indexer in await search_indexer_client.get_indexers():
            indexer_list.append({"indexer_name": indexer.name, "target_index_name": indexer.target_index_name})

        await search_indexer_client.close()

        return indexer_list

    async def cognitive_search_run_indexer(self, index_name):
        """cognitive_search_run_indexer"""
        search_indexer_client = SearchIndexerClient(self.azure_search_endpoint, self.cognitive_search_credential)
        # indexer = await search_indexer_client.get_indexer(indexer_name)
        await search_indexer_client.run_indexer(index_name)

        await search_indexer_client.close()

    async def cognitive_search_get_indexer_status(self, indexer_name):
        """cognitive_search_get_indexer_status"""
        search_indexer_client = SearchIndexerClient(self.azure_search_endpoint, self.cognitive_search_credential)
        # indexer = await search_indexer_client.get_indexer(indexer_name)
        result = await search_indexer_client.get_indexer_status(indexer_name)

        await search_indexer_client.close()
        return result

    async def query_openai(self, query, messages):
        """Query Open AI

        Args:
            query (str): ì§ˆì˜
            messages (list): Messages

        Returns:
            dict: messages & answer
        """
        if len(messages) == 0:
            messages = [
                {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
                {"role": "user", "content": query},
            ]
        else:
            messages.append({"role": "user", "content": query})

        response = openai.ChatCompletion.create(engine="chat", messages=messages)
        messages.append(response["choices"][0]["message"])

        result = {"messages": messages, "answer": response["choices"][0]["message"]["content"]}

        return result

    async def execute_openai(self, question, index_name, vector_store_name):
        """Excute OpenAI"""
        return_dict = {"question": question, "answer": 'ìë£Œë¥¼ ì°¾ì§€ ëª»í•˜ì˜€ìŠµë‹ˆë‹¤.', "reference_file": []}
        # ë¡œê·¸ ì €ì¥
        start = time.time()
        chat_request_history = ChatRequestHistory(selected_index=index_name, query="test", user_id=22, status=ChatRequestHistory.Statues.running)
        MysqlEngine.session.add(chat_request_history)
        MysqlEngine.session.commit()

        # Call Cognitive API
        url = self.azure_search_endpoint + "/indexes/" + index_name + "/docs"
        params = {
            "api-version": self.azure_search_api_version,
            "search": question,
            "queryLanguage": "en-US",
            "queryType": "semantic",
            "semanticConfiguration": "semantic-config",
            "select": "*",
            "$count": "true",
            "speller": "lexicon",
            "$top": "5",
            "answers": "extractive|count-3",
            "captions": "extractive|highlight-false",
        }

        resp = requests.get(url, params=params, headers=self.headers)
        search_results = resp.json()  # ê²°ê³¼ê°’

        if resp.status_code != 200:
            chat_request_history.answer = return_dict['answer']
            chat_request_history.status = ChatRequestHistory.Statues.fail
            chat_request_history.response_at = CommonUtils.get_kst_now()
            chat_request_history.running_time = CommonUtils.get_running_time(start, time.time())
            MysqlEngine.session.commit()
            raise APIException(resp.status_code, "Cognitive Search API ì‹¤íŒ¨", error=resp.json())

        if search_results["@odata.count"] == 0:
            chat_request_history.answer = return_dict['answer']
            chat_request_history.status = ChatRequestHistory.Statues.success
            chat_request_history.response_at = CommonUtils.get_kst_now()
            chat_request_history.running_time = CommonUtils.get_running_time(start, time.time())
            MysqlEngine.session.commit()
            return return_dict
        else:
            file_content = OrderedDict()
            for result in search_results["value"]:
                if result["@search.rerankerScore"] > 0.03:  # Semantic Search ìµœëŒ€ ì ìˆ˜ 4ì 
                    file_content[result["metadata_storage_path"]] = {
                        "chunks": result["pages"][:1],
                        "caption": result["@search.captions"][0]["text"],
                        "score": result["@search.rerankerScore"],
                        "file_name": result["metadata_storage_name"],
                    }

            # AzureOpenAI Service ì—°ê²°
            docs = []
            for key, value in file_content.items():
                for page in value["chunks"]:
                    docs.append(Document(page_content=page, metadata={"source": value["file_name"]}))

            if len(docs) == 0:
                chat_request_history.answer = return_dict['answer']
                chat_request_history.status = ChatRequestHistory.Statues.success
                chat_request_history.response_at = CommonUtils.get_kst_now()
                chat_request_history.running_time = CommonUtils.get_running_time(start, time.time())
                MysqlEngine.session.commit()
                return return_dict

            # Embedding ëª¨ë¸ ìƒì„±
            # ì•„ë˜ì†ŒìŠ¤ì—ì„œ chunk_size=1 ì´ ì•„ë‹Œ ë‹¤ë¥¸ ê°’ì„ ë„£ìœ¼ë©´ ë‹¤ìŒ ì†ŒìŠ¤ì—ì„œ ì—ëŸ¬ê°€ ë‚œë‹¤.
            embeddings = OpenAIEmbeddings(
                model="text-embedding-ada-002", chunk_size=1, openai_api_key=self.azure_openai_key
            )  # Azure OpenAI embedding ì‚¬ìš©ì‹œ ì£¼ì˜

            # Vector Store ìƒì„±
            vector_store = FAISS.from_documents(docs, embeddings)
            # if vector_store_name == 'Chroma':
            # persist_directory = "db"
            # 	vector_store = Chroma.from_documents(docs, embeddings)
            # 	vector_store = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=persist_directory)

            # LangChainğŸ¦œ & Azure GPTğŸ¤– ì—°ê²°
            llm = AzureChatOpenAI(
                deployment_name="gpt-35-turbo",
                openai_api_key=self.azure_openai_key,
                openai_api_base=self.azure_openai_endpoint,
                openai_api_version=self.azure_openai_api_version,
                temperature=0.0,
                max_tokens=1000,
            )

            # https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html
            qa = RetrievalQAWithSourcesChain.from_chain_type(
                llm=llm,
                # chain_type='stuff',
                chain_type="map_reduce",
                retriever=vector_store.as_retriever(),
                return_source_documents=True,
            )

            prompt_prefix = 'Think in English and answer in Korean  \n\n'
            result = qa({"question":  prompt_prefix + question})

            print("ì§ˆë¬¸ :", question)
            print("ë‹µë³€ :", result["answer"])
            print("ğŸ“„ ì°¸ê³  ìë£Œ :", result["sources"].replace(",", "\n"))
            return_dict['answer'] = result['answer'].replace('\n', '')
            return_dict['reference_file'] = result["sources"].split(',')
            # return_dict['reference_file_link'] = result["sources"]

            chat_request_history.answer = result["answer"]
            chat_request_history.status = ChatRequestHistory.Statues.success
            chat_request_history.response_at = CommonUtils.get_kst_now()
            chat_request_history.running_time = CommonUtils.get_running_time(start, time.time())
            chat_request_history.reference_file = result["sources"].replace(",", "\n")
            MysqlEngine.session.commit()

            return return_dict
